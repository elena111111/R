# Метрические алгоритмы классификации

## knn - метод k ближайших соседей.
Дана выборка ирисов Фишера(150 элементов), в ней 3 класса(*setosa*, *versicolor*, *virginica*). 
Мы хотим классифицировать множество точек *{z}* по 2м признакам (Petal.Length, Petal.Width). Эти же признаки - координаты точек на графике.
Массив *xl* хранит координаты точек исходной выборки и название класса, к которому относится соответствующая точка.

Для каждой точки *z* построим вспомогательный вектор *distances*, в котором будем хранить расстояния от точки *z* до каждой точки из выборки.
Массив *orderedxl* - это массив *xl*, отсортированный так, чтобы точки шли в порядке увеличения расстояния от *z* до точки из выборки.
Теперь заберём из *orderedxl* только первые *k* строк (получим *k* ближайших соседей) и в этих строках оставим только столбец названий классов (массив *classes*).
Точка *z* относится к тому классу, который чаще всего встречается в *classes*.

Оптимальное *k* подбирается по *LOO* (скользящий контроль), который работает следующим образом: 
Пусть переменная *Q = 0*.
Из выборки(*X*) будем исключать по одной точке (пусть будет точка *zi*) - получим выборку *X2*. 
Теперь запустим алгоритм(*knn*), как будто мы хотим классифицировать точку *zi*, и имеем выборку *X2*.
Если алгоритм ошибся, то к величине *Q* прибавим 1.
Когда мы таким образом переберём все точки выборки, вычислим *Loo = Q/l*, где *l* - количество точек в выборке *X*.

Будем делать это для разных *k* от 1 до *l*.
Оптимальным будет *k*, при котором величина *Loo* минимальна.

Результат работы программы: 

![alt text](https://github.com/elena111111/R/blob/master/knn/knn.png)

Зависимость *Loo* от *k*:

![alt text](https://github.com/elena111111/R/blob/master/knn/knn_loo.png)


## Алгортим k взвешенных ближайших соседей (wknn).
Имеется выборка *X* (ирисы Фишера), и 3 класса (*setosa*, *versicolor*, *virginica*). 
Мы хотим классифицировать множество точек *{z}*.
Классификацию проводим по двум признакам (Petal.Length, Petal.Width), они же являются координатами точек.

*distances* - это вектор расстояний от точки *z* до каждой точки из выборки *X*.
*orderedxl* - это массив *xl*, отсортированный по возрастанию расстояний от точки *z* до каждой точки из выборки *X*.
Мы выбрали весовую функцию *q^i*.
Для *k* ближайших соседей построим соответствующие веса.
В массиве *classes* будет *k* строк, а в столбцах название класса и вес точки. 
Осталось найти сумму весов для каждого класса отдельно в *classes* (это массив *ans*).
Ответом будет тот класс, вес которого максимален в *ans*.

Значение *q* подбирается по *LOO*, который работает следующим образом:
Пусть переменная *Q = 0*.
Из выборки(*X*) будем исключать по одной точке (пусть будет точка *zi*) - получим выборку *X2*. 
Теперь запустим алгоритм(*wknn*), как будто мы хотим классифицировать точку *zi*, и имеем выборку *X2*.
Если алгоритм ошибся, то к величине *Q* прибавим 1.
Когда мы таким образом переберём все точки выборки, вычислим *Loo = Q/l*, где *l* - количество точек в выборке *X*.

Будем делать это для разных *q*, которые могут находиться в интервале *(0; 1)*.
Оптимальным будет *q*, при котором величина *Loo* минимальна.

Результат работы программы: 

![alt text](https://github.com/elena111111/R/blob/master/wknn/wknn.png)

Зависимость *Loo* от *q*:

![alt text](https://github.com/elena111111/R/blob/master/wknn/wknn_loo_q.png)

## Алгоритм парзеновского окна (pw).
Имеется выборка *X* (ирисы Фишера), и 3 класса (*setosa*, *versicolor*, *virginica*). 
Мы хотим классифицировать множество точек *{z}*.
Классификацию проводим по двум признакам (Petal.Length, Petal.Width), они же являются координатами точек.

*distances_weighed[ , 1]* - это расстояния от точки *z* до каждой точки из выборки *X*.
*distances_weighed[ , 2]* - значение весовой функции для каждой точки из выборки.
Весовая функция зависит от расстояния от точки *z* до точки из выборки, а также от выбора параметра *h* (ширина окна) и ядра K, которые подбираются по LOO (принцип работы уже был описан в прдыдущих алгоритмах).
Наглядно: мы строим вокруг точки *z*(центр окна) окрестность радиуса *h*, и смотрим, суммарный вес какого класса в этой окрестности больше.
Для каждого ядра получилось одинаковое значение минимального *Loo*. Так что мы убедились, что выбор ядра слабо влияет на классификацию.
В таблице *classes* хранятся расстояния от *z* до точек из *X*, веса точек из *X* и название класса каждой точки из *X*.
Суммируем веса каждого класса (матрица *ans*).
Ответом будет класс, для которого суммарный вес максимален в *ans*.

Стоит отметить, что данный алгоритм плохо подходит для неравномерно распределённой выборки (в окно одинаковой ширины попадает очень разное количество объектов). 
В этом случае лучше использовать алгоритм парзеновского окна с переменной шириной окна (описан ниже).

Результат работы программы / Зависимость *loo* от *h* (для разных ядер):

1) Прямоугольное ядро:

![alt text](https://github.com/elena111111/R/blob/master/pw/pw_core_rect_and_loo.png)

2) Треугольное ядро:

![alt text](https://github.com/elena111111/R/blob/master/pw/pw_core_triang_and_loo.png)

3) Ядро Епанечникова:

![alt text](https://github.com/elena111111/R/blob/master/pw/pw_core_epan_and_loo.png)

4) Квартическое ядро:

![alt text](https://github.com/elena111111/R/blob/master/pw/pw_core_quart_and_loo.png)

5) Гауссовское ядро: 

![alt text](https://github.com/elena111111/R/blob/master/pw/pw_core_gauss_and_loo.png)

## Алгоритм парзеновского окна с переменной шириной окна (varpw).
Имеется выборка *X* (ирисы Фишера), и 3 класса (*setosa*, *versicolor*, *virginica*). 
Мы хотим классифицировать множество точек *{z}*.
Классификацию проводим по двум признакам (Petal.Length, Petal.Width), они же являются координатами точек.
*distances* - это вектор расстояний от точки *z* до каждой точки из выборки *X*.
*orderedxl* - это массив *xl*, отсортированный по возрастанию расстояний от точки *z* до каждой точки из выборки *X*.
*distances_s* - отсортированный вектор расстояний.
*weights* - вектор весов для *k* ближайших соседей.
Для весовой функции нам нужно выбрать ядро(в примере работы программы используется прямоугольное).
Аргумент ядра - расстояние от *z* до *i*-го соседа точки *z* (*i* от *1* до *k*), деленое на расстояние от *z* до (*k+1*)-го соседа.

Возьмем из *orderedxl* первые *k* строк, допишем к ним соответствующие веса и оставим только столбцы названий классов и весов - получим массив *classes*.
Ответом будет тот класс, суммарный вес которого максимален в *classes*. 

Данный метод подходит для неравномерно распределенной выборки.

Пример работы программы:

![alt text](https://github.com/elena111111/R/blob/master/varpw/varpw_core_rect.png)

## Метод потенциальных функций 
Имеется выборка *X* (ирисы Фишера), и 3 класса (*setosa*, *versicolor*, *virginica*). 
Мы хотим классифицировать множество точек *{z}*.
Классификацию проводим по двум признакам (Petal.Length, Petal.Width), они же являются координатами точек.

В методе парзеновского окна мы помещали центр окна в классифицируемый объект, а теперь построим окрестности вокруг обучающих объектов. 
Причем каджая окрестность будет иметь свой потенциал - велину, показывающую, насколько сильно это окно влияет на другие элементы. То есть даже при одинаковой ширине окна *h* это влияние может быть разное.

Первым мы вызываем метод *gamma*, в теле которого происходит следующее: 
*g[dim(iris)[1]]* - это вектор потенциалов, изначально заполненный нулями. 

Вспомним:
Вспомогательный метод *loo* запускает алгоритм pf с текущими параметрами *g, h, K*(функция ядра) для выборки *X*, исключает из *X* по одной точке, 
тестирует алгоритм *pf* на оставшихся объектах и сравнивает результат работы алгоритма с эталонным результатом. Если ответы не совпали, то величину ошибок увеличиваем на 1. 
Суммарную величину ошибок делим на размерность выборки *X*. Метод вернет число от 0 до 1.
 
*eps* - это максимально допустимое число ошибок (от 0 до 1).
Если результат работы *loo > eps*, значит надо улучшить вектор *g*: 
Выберем случайным образом элемент *xi* из *X*.
Если алгортим *pf(X, xi, g, K, h)* ошибается, значит в точке *xi* нужно увеличить потенциал на 1.

Если *loo* с текущими пераметрами вернет число *<= eps*, значит мы достигли преемлемой доли ошибок, и *g* больше улучшать не будем. Вернем вектор *g*.

Шируну окна *h* можно подбирать индивидуально для каждого объекта, но в алгоритме не указывается, как именно (недостаток). 
В данном случае эта величина взята из метода парзеновского окна, и одинакова для всех окон.

Метод *pf* работает аналогично с методом парзеновского окна, только значение функции ядра ещё домножается на *g*:
*z* - классифицируемая точка.
*distances_weighed[ , 1]* - это расстояния от точки *z* до каждой точки из выборки *X*.
*distances_weighed[ , 2]* - значение весовой функции для каждой точки из выборки *X*.
*classes* - это *distances_weighed*, к которому добавили столбец соответствующих названий классов. 
Ответом для *z* будет тот класс, сумарный вес которого максимален в *classes*.

Пример работы программы(для гауссовского ядра):

![alt text](https://github.com/elena111111/R/blob/master/pf/pf_gauss_015_center.png)

Черным показаны центры окон с ненулевым потенциалом (он получился в них равен 1).

## Алгоритм STOLP
 



 
